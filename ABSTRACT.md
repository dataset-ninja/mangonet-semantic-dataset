In the pursuit of enhancing mango yield estimation, the authors of the **The MangoNet Semantic Dataset** introduce a method for detecting and counting mangoes within RGB images. The dataset contains 11,096 image patches, each sized at 200Ã—200 pixels, extracted from a pool of 40 images. Testing is subsequently conducted on 1500 image patches generated from four distinct test images. These images are sourced from a mango orchard during the pre-harvest stage, under open field conditions. The proposed methodology leverages MangoNet, a deep convolutional neural network architecture designed for mango detection through semantic segmentation. 

India, as the world's foremost mango producer, contributes to over 52% of the global production, totaling around 23 million metric tonnes. A significant portion of these mangoes, approximately 30%, is sold to pre-harvest contractors. The value of this crop is contingent upon accurate yield estimation, a task currently executed manually. Manual yield estimation involves sampling blocks within the mango orchards, often in conditions characterized by heat and humidity, common to tropical climates where mangoes thrive. This manual process imposes limitations on the accuracy of orchard assessment, rendering it labor-intensive, time-consuming, error-prone, and subject to considerable variability.

## Data Acquisition

The dataset includes images of mango trees, featuring mangoes ready for harvest within a week. These images were captured using an RGB camera with spatial resolution. The acquisition took place during a bright afternoon in April, between 1:00 pm and 3:00 pm, amid tropical summer conditions. Images that adequately represented mangoes were selected for subsequent analysis. The experiment site is a mango orchard located in Mudimadagu village, situated at Latitude 13.56N and Longitude 78.36E within the Rayalpad sub-division of the Srinivaspur taluk. This region is renowned for mango cultivation within the southeastern part of the Indian peninsula.

Ground truth data was meticulously generated using an open-source image editing tool. Annotation was conducted for binary classification, distinguishing between mango and non-mango classes. Mango pixels were distinctly marked in green (<i>Note, that in DatasetNinja its color has been changed to magenta</i>), while non-mango regions were designated in black. Each mango pixel group was enclosed within an annotated box, and each box exclusively contained one mango. The annotated box coordinates played a crucial role in evaluating mango detection and counting.
